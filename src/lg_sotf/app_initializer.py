"""
Application initializer for LG-SOTF.

This module provides the main application lifecycle management including:
- Component initialization and dependency injection
- Continuous alert ingestion and processing
- Health monitoring and metrics collection
- Graceful shutdown with resource cleanup
"""

import asyncio
import logging
import signal
from datetime import datetime, timedelta
from typing import Optional, Set

from lg_sotf.audit.logger import AuditLogger
from lg_sotf.audit.metrics import MetricsCollector
from lg_sotf.core.config.manager import ConfigManager
from lg_sotf.core.exceptions import LG_SOTFError
from lg_sotf.core.state.manager import StateManager
from lg_sotf.core.workflow import WorkflowEngine
from lg_sotf.storage.postgres import PostgreSQLStorage
from lg_sotf.storage.redis import RedisStorage


BANNER = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                                          ‚ïë
‚ïë  ‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä              
‚ïë  ‚†Ä‚¢∏‚†â‚£π‚†ã‚†â‚¢â‚°ü‚¢©‚¢ã‚†ã‚£Ω‚°ª‚†≠‚¢Ω‚¢â‚†Ø‚†≠‚†≠‚†≠‚¢Ω‚°ç‚¢π‚°ç‚†ô‚£Ø‚†â‚†â‚†â‚†â‚†â‚£ø‚¢´‚†â‚†â‚†â‚¢â‚°ü‚†â‚¢ø‚¢π‚†â‚¢â‚£â‚¢ø‚°ù‚°â‚¢©‚¢ø‚£ª‚¢ç‚†â‚†â‚†©‚¢π‚£ü‚°è‚†â‚†π‚°â‚¢ª‚°ç‚°á  
‚ïë  ‚†Ä‚¢∏‚¢†‚¢π‚†Ä‚†Ä‚¢∏‚†Å‚£º‚†Ä‚£º‚°ù‚†Ä‚†Ä‚¢∏‚†ò‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚¢ø‚†Ä‚°ü‚°Ñ‚†π‚££‚†Ä‚†Ä‚†ê‚†Ä‚¢∏‚°ò‚°Ñ‚£§‚†Ä‚°º‚†Å‚†Ä‚¢∫‚°ò‚†â‚†Ä‚†Ä‚†Ä‚†´‚£™‚£å‚°å‚¢≥‚°ª‚£¶‚†Ä‚†Ä‚¢É‚°Ω‚°º‚°Ä‚†Ä‚¢£‚¢∏‚†∏‚°á      
‚ïë  ‚†Ä‚¢∏‚°∏‚¢∏‚†Ä‚†Ä‚£ø‚†Ä‚£á‚¢†‚°ø‚†Ä‚†Ä‚†Ä‚†∏‚°á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚¢á‚†∏‚†ò‚°Ä‚†ª‚£á‚†Ä‚†Ä‚†Ñ‚†Ä‚°á‚¢£‚¢õ‚†Ä‚°á‚†Ä‚†Ä‚£∏‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ò‚†Ñ‚¢ª‚°Ä‚†ª‚£ª‚£ß‚†Ä‚†Ä‚†É‚¢ß‚°á‚†Ä‚¢∏‚¢∏‚°á‚°á  
‚ïë  ‚†Ä‚¢∏‚°á‚¢∏‚£†‚†Ä‚£ø‚¢†‚£ø‚°æ‚†Å‚†Ä‚¢Ä‚°Ä‚†§‚¢á‚£Ä‚£ê‚£Ä‚†Ä‚†§‚¢Ä‚†à‚†¢‚°°‚°à‚¢¶‚°ô‚£∑‚°Ä‚†Ä‚†Ä‚¢ø‚†à‚¢ª‚£°‚†Å‚†Ä‚¢Ä‚†è‚†Ä‚†Ä‚†Ä‚¢Ä‚†Ä‚†Ñ‚£Ä‚£ê‚£Ä‚£ô‚†¢‚°å‚£ª‚£∑‚°Ä‚¢π‚¢∏‚°Ö‚†Ä‚¢∏‚†∏‚°á‚°á  
‚ïë  ‚†Ä‚¢∏‚°á‚¢∏‚£ü‚†Ä‚¢ø‚¢∏‚°ø‚†Ä‚£Ä‚£∂‚£∑‚£æ‚°ø‚†ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∂‚£¨‚°Ä‚†ê‚†∞‚£Ñ‚†ô‚†™‚£ª‚£¶‚°Ä‚†ò‚£ß‚†Ä‚†ô‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£®‚£¥‚£æ‚£ø‚†ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∂‚£Ø‚£ø‚£º‚¢º‚°á‚†Ä‚¢∏‚°á‚°á‚°á  
‚ïë  ‚†Ä‚¢∏‚¢ß‚†Ä‚£ø‚°Ö‚¢∏‚£º‚°∑‚£æ‚£ø‚°ü‚†ã‚£ø‚†ì‚¢≤‚£ø‚£ø‚£ø‚°ü‚†ô‚£ø‚†õ‚¢Ø‚°≥‚°Ä‚†à‚†ì‚†Ñ‚°à‚†ö‚†ø‚£ß‚£å‚¢ß‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£∫‚†ü‚¢´‚°ø‚†ì‚¢∫‚£ø‚£ø‚£ø‚†è‚†ô‚£è‚†õ‚£ø‚£ø‚£æ‚°á‚¢Ä‚°ø‚¢†‚†Ä‚°á  
‚ïë  ‚†Ä‚¢∏‚¢∏‚†Ä‚¢π‚£∑‚°Ä‚¢ø‚°Å‚†Ä‚†ª‚£á‚†Ä‚£á‚†Ä‚†ò‚£ø‚£ø‚°ø‚†Å‚†ê‚£â‚°Ä‚†Ä‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†ì‚†≥‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†ã‚†Ä‚†ò‚°á‚†Ä‚†∏‚£ø‚£ø‚†ü‚†Ä‚¢à‚£â‚¢†‚°ø‚†Å‚£º‚†Å‚£º‚†É‚£º‚†Ä‚°á  
‚ïë  ‚†Ä‚¢∏‚†∏‚£Ä‚†à‚£Ø‚¢≥‚°ò‚£á‚†Ä‚†Ä‚†à‚°Ç‚£ú‚£Ü‚°Ä‚†Ä‚†Ä‚¢Ä‚£Ä‚°¥‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ω‚£Ü‚£Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£ú‚†ï‚°ä‚†Ä‚£∏‚†á‚£º‚°ü‚¢†‚†è‚†Ä‚°á  
‚ïë  ‚†Ä‚¢∏‚†Ä‚°ü‚†Ä‚¢∏‚°Ü‚¢π‚°ú‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚†ã‚£æ‚°è‚°á‚°é‚°á‚†Ä‚°á  
‚ïë  ‚†Ä‚¢∏‚†Ä‚¢É‚°Ü‚†Ä‚¢ø‚°Ñ‚†ë‚¢Ω‚£Ñ‚†Ä‚†Ä‚†Ä‚¢Ä‚†Ç‚††‚¢Å‚†à‚†Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚††‚†Ç‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ñ‚°ê‚¢Ä‚†Ç‚†Ä‚†Ä‚£†‚£Æ‚°ü‚¢π‚£Ø‚£∏‚£±‚†Å‚†Ä‚°á  
‚ïë  ‚†Ä‚†à‚†â‚†â‚†ã‚†â‚†â‚†ã‚†â‚†â‚†â‚†ã‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†â‚†ã‚°ü‚†â‚†â‚°ø‚†ã‚†ã‚†ã‚†â‚†â‚†Å  
‚ïë                                                                               
‚ïë                  LangGraph SOC Triage & Orchestration Framework (LG-SOTF)                 
‚ïë                      Version 1.0.0 - Copy Right 2025                                     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

class LG_SOTFApplication:
    """Main application class for LG-SOTF."""

    def __init__(self, config_path: Optional[str] = None, setup_signal_handlers: bool = True):
        """Initialize the application.

        Args:
            config_path: Path to configuration file
            setup_signal_handlers: Whether to setup signal handlers (disable when running under uvicorn)
        """
        self.config_path = config_path
        self.config_manager = None
        self.state_manager = None
        self.workflow_engine = None
        self.audit_logger = None
        self.metrics = None
        self.postgres_storage = None
        self.redis_storage = None

        # Application state
        self.running = False
        self.initialized = False

        # Task tracking for graceful shutdown
        self._active_tasks: Set[asyncio.Task] = set()
        self._shutdown_event = asyncio.Event()

        # Ingestion tracking
        self._last_ingestion_poll: Optional[datetime] = None
        self._last_health_check: Optional[datetime] = None
        self._ingestion_lock = asyncio.Lock()

        # Setup signal handlers (only when not running under uvicorn)
        if setup_signal_handlers:
            self._setup_signal_handlers()

    def _setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown."""
        def signal_handler(signum, frame):
            """Handle shutdown signals."""
            logging.info(f"Received signal {signum}, initiating graceful shutdown...")
            self.running = False
            # Use call_soon_threadsafe to safely set the event from signal handler
            try:
                loop = asyncio.get_running_loop()
                loop.call_soon_threadsafe(self._shutdown_event.set)
            except RuntimeError:
                # If no loop is running, just set it directly (shouldn't happen in normal flow)
                self._shutdown_event.set()

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    async def initialize(self):
        """Initialize all application components.

        Raises:
            LG_SOTFError: If initialization fails
        """
        try:
            logging.info("=== Initializing LG-SOTF Application ===")

            # Load configuration
            self.config_manager = ConfigManager(self.config_path)
            logging.info("‚úì Configuration loaded")

            # Validate configuration
            self.config_manager.validate()
            logging.info("‚úì Configuration validated")

            # Initialize audit and metrics
            self.audit_logger = AuditLogger()
            self.metrics = MetricsCollector(self.config_manager)
            logging.info("‚úì Audit and metrics initialized")

            # Initialize storage backends
            await self._initialize_storage()
            logging.info("‚úì Storage backends initialized")

            # Initialize state manager
            self.state_manager = StateManager(self.postgres_storage)
            logging.info("‚úì State manager initialized")

            # Initialize workflow engine (handles agent initialization)
            # Pass Redis storage and let the workflow engine create the tool orchestrator
            self.workflow_engine = WorkflowEngine(
                self.config_manager,
                self.state_manager,
                redis_storage=self.redis_storage,
                tool_orchestrator=None  # Created internally by workflow engine
            )
            await self.workflow_engine.initialize()
            logging.info("‚úì Workflow engine initialized")

            # Verify agents are registered
            from lg_sotf.agents.registry import agent_registry
            stats = agent_registry.get_registry_stats()
            logging.info(
                f"‚úì Agent registry: {stats['agent_types_count']} types, "
                f"{stats['agent_instances_count']} instances, "
                f"{len(stats['initialized_agents'])} initialized"
            )

            # Log application start
            self.audit_logger.log_application_start(
                config_path=self.config_path,
                version="0.1.0"
            )

            self.initialized = True
            logging.info(BANNER)

        except Exception as e:
            logging.error(f"Failed to initialize application: {e}", exc_info=True)
            raise LG_SOTFError(f"Application initialization failed: {e}")

    async def _initialize_storage(self):
        """Initialize storage backends.

        Raises:
            Exception: If storage initialization fails
        """
        try:
            # Initialize PostgreSQL
            db_config = self.config_manager.get_database_config()
            connection_string = (
                f"postgresql://{db_config.username}:{db_config.password}@"
                f"{db_config.host}:{db_config.port}/{db_config.database}"
            )

            self.postgres_storage = PostgreSQLStorage(connection_string)
            await self.postgres_storage.initialize()
            logging.info(f"  - PostgreSQL connected: {db_config.host}:{db_config.port}")

            # Initialize Redis
            redis_config = self.config_manager.get_redis_config()
            redis_password = f":{redis_config.password}@" if redis_config.password else ""
            redis_connection_string = (
                f"redis://{redis_password}{redis_config.host}:{redis_config.port}/{redis_config.db}"
            )

            self.redis_storage = RedisStorage(redis_connection_string)
            await self.redis_storage.initialize()
            logging.info(f"  - Redis connected: {redis_config.host}:{redis_config.port}")

        except Exception as e:
            logging.error(f"Failed to initialize storage: {e}", exc_info=True)
            raise

    async def run(self):
        """Run the main application loop.

        This method handles:
        - Continuous alert ingestion and processing
        - Periodic health checks
        - Graceful shutdown on signal
        """
        try:
            self.running = True
            logging.info("üöÄ LG-SOTF Application Started")
            logging.info("Press Ctrl+C to shutdown gracefully\n")

            # Create background tasks
            ingestion_task = asyncio.create_task(self._ingestion_loop())
            health_check_task = asyncio.create_task(self._health_check_loop())

            # Wait for shutdown signal
            await self._shutdown_event.wait()

            # Cancel background tasks
            logging.info("Stopping background tasks...")
            ingestion_task.cancel()
            health_check_task.cancel()

            # Wait for tasks to complete
            await asyncio.gather(ingestion_task, health_check_task, return_exceptions=True)

        except asyncio.CancelledError:
            logging.info("Main loop cancelled")
        except Exception as e:
            logging.error(f"Unexpected error in main loop: {e}", exc_info=True)
        finally:
            await self.shutdown()

    async def _ingestion_loop(self):
        """Continuous ingestion loop.

        Polls configured sources at regular intervals and processes alerts.
        """
        try:
            while self.running:
                try:
                    await self._process_alerts()
                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logging.error(f"Error in ingestion loop: {e}", exc_info=True)
                    self.metrics.increment_counter("ingestion_loop_errors")
                    await asyncio.sleep(5)  # Back off on error

                # Sleep briefly to prevent tight loop
                await asyncio.sleep(1)

        except asyncio.CancelledError:
            logging.info("Ingestion loop cancelled")

    async def _health_check_loop(self):
        """Periodic health check loop.

        Performs system health checks at regular intervals.
        Responsive to shutdown signals.
        """
        try:
            while self.running:
                try:
                    await self._perform_health_checks()
                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logging.error(f"Error in health check loop: {e}", exc_info=True)
                    self.metrics.increment_counter("health_check_errors")

                # Wait before next health check, but wake up on shutdown
                try:
                    await asyncio.wait_for(self._shutdown_event.wait(), timeout=60)
                    # If we get here, shutdown was triggered
                    break
                except asyncio.TimeoutError:
                    # Timeout is normal, continue to next health check
                    pass

        except asyncio.CancelledError:
            logging.info("Health check loop cancelled")

    async def _process_alerts(self):
        """Process alerts from ingestion sources.

        This method:
        - Respects polling interval configuration
        - Enforces max concurrent alert limit
        - Tracks tasks for graceful shutdown
        """
        # Check if ingestion agent is available
        if not self.workflow_engine or "ingestion" not in self.workflow_engine.agents:
            return

        ingestion_agent = self.workflow_engine.agents["ingestion"]

        # Get polling configuration
        ingestion_config = self.config_manager.get_agent_config("ingestion")
        polling_interval = ingestion_config.get("polling_interval", 60)
        max_concurrent = ingestion_agent.max_concurrent_alerts

        # Check if it's time to poll
        if self._last_ingestion_poll is not None:
            time_since_poll = (datetime.utcnow() - self._last_ingestion_poll).total_seconds()
            if time_since_poll < polling_interval:
                return

        # Use lock to prevent concurrent polling
        if self._ingestion_lock.locked():
            return

        async with self._ingestion_lock:
            try:
                # Check active task count
                active_count = len(self._active_tasks)
                if active_count >= max_concurrent:
                    logging.warning(
                        f"Max concurrent alerts reached ({active_count}/{max_concurrent}), "
                        "skipping this poll cycle"
                    )
                    self.metrics.increment_counter("ingestion_poll_skipped_max_concurrent")
                    return

                # Poll for new alerts
                logging.debug("Polling ingestion sources...")
                new_alerts = await ingestion_agent.poll_sources()

                if not new_alerts:
                    self._last_ingestion_poll = datetime.utcnow()
                    return

                logging.info(f"üì• Ingestion: Found {len(new_alerts)} new alerts")
                self.metrics.increment_counter("ingestion_alerts_received", len(new_alerts))

                # Process alerts respecting concurrency limit
                processed_count = 0
                for alert in new_alerts:
                    # Check if we can process more alerts
                    if len(self._active_tasks) >= max_concurrent:
                        remaining = len(new_alerts) - processed_count
                        logging.warning(
                            f"Max concurrent limit reached, "
                            f"queueing {remaining} alerts for next cycle"
                        )
                        self.metrics.increment_counter("ingestion_alerts_queued", remaining)
                        break

                    try:
                        # Create workflow task
                        task = asyncio.create_task(
                            self._process_single_workflow(alert["id"], alert)
                        )

                        # Track task
                        self._active_tasks.add(task)
                        task.add_done_callback(self._active_tasks.discard)

                        processed_count += 1

                    except Exception as e:
                        logging.error(
                            f"Failed to create workflow task for alert {alert.get('id', 'unknown')}: {e}",
                            exc_info=True
                        )
                        self.metrics.increment_counter("workflow_creation_errors")

                logging.info(
                    f"‚úì Created {processed_count} workflow tasks "
                    f"({len(self._active_tasks)} active)"
                )
                self.metrics.set_gauge("active_workflow_tasks", len(self._active_tasks))

                # Update last poll time
                self._last_ingestion_poll = datetime.utcnow()
                self.metrics.record_histogram("ingestion_poll_interval", polling_interval)

            except Exception as e:
                logging.error(f"Ingestion polling error: {e}", exc_info=True)
                self.metrics.increment_counter("ingestion_poll_errors")

    async def _process_single_workflow(self, alert_id: str, alert_data: dict):
        """Process a single alert through the workflow.

        Args:
            alert_id: Alert identifier
            alert_data: Alert data dictionary (already ingested by polling loop)
        """
        start_time = datetime.utcnow()

        try:
            logging.debug(f"Processing workflow for alert {alert_id}")

            # Skip ingestion node since alert is already ingested by the polling loop
            result = await self.workflow_engine.execute_workflow(
                alert_id,
                alert_data,
                skip_ingestion=True  # Alert already normalized by ingestion agent polling
            )

            # Calculate processing time
            processing_time = (datetime.utcnow() - start_time).total_seconds()

            logging.info(
                f"‚úì Alert {alert_id} processed: "
                f"status={result.get('triage_status', 'unknown')}, "
                f"confidence={result.get('confidence_score', 0)}, "
                f"time={processing_time:.2f}s"
            )

            # Record metrics
            self.metrics.increment_counter("workflow_success")
            self.metrics.record_histogram("workflow_processing_time", processing_time)

        except asyncio.CancelledError:
            logging.info(f"Workflow for alert {alert_id} cancelled (shutdown)")
            raise
        except Exception as e:
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            logging.error(
                f"‚úó Failed to process alert {alert_id}: {e}",
                exc_info=True
            )
            self.metrics.increment_counter("workflow_errors")
            self.metrics.record_histogram("workflow_error_time", processing_time)

    async def _perform_health_checks(self):
        """Perform periodic health checks on all components."""
        # Check if it's time for health check (every 60 seconds)
        if self._last_health_check is not None:
            time_since_check = (datetime.utcnow() - self._last_health_check).total_seconds()
            if time_since_check < 60:
                return

        try:
            logging.debug("Performing health checks...")
            health_status = await self.health_check()

            if health_status:
                logging.debug("‚úì All components healthy")
            else:
                logging.warning("‚ö† Some components unhealthy")

            self.metrics.set_gauge("health_check_status", 1 if health_status else 0)
            self._last_health_check = datetime.utcnow()

        except Exception as e:
            logging.error(f"Health check error: {e}", exc_info=True)
            self.metrics.increment_counter("health_check_errors")

    async def shutdown(self):
        """Shutdown the application gracefully.

        This method:
        - Cancels all active workflow tasks
        - Shuts down agents
        - Closes storage connections
        - Cleans up resources
        """
        try:
            logging.info("\n=== Shutting Down LG-SOTF Application ===")

            # Cancel active workflow tasks
            if self._active_tasks:
                task_count = len(self._active_tasks)
                logging.info(f"Cancelling {task_count} active workflow tasks...")

                for task in self._active_tasks:
                    if not task.done():
                        task.cancel()

                # Wait for tasks to complete with timeout
                try:
                    await asyncio.wait_for(
                        asyncio.gather(*self._active_tasks, return_exceptions=True),
                        timeout=10.0
                    )
                    logging.info(f"‚úì All {task_count} workflow tasks cancelled")
                except asyncio.TimeoutError:
                    logging.warning(f"‚ö† Some workflow tasks did not complete within timeout")

            # Log application shutdown
            if self.audit_logger:
                self.audit_logger.log_application_shutdown()

            # Shutdown agents
            await self._shutdown_agents()

            # Close storage connections
            await self._shutdown_storage()

            # Shutdown metrics collection
            if self.metrics:
                try:
                    self.metrics.shutdown()
                    logging.info("‚úì Metrics collection stopped")
                except Exception as e:
                    logging.warning(f"‚ö† Error shutting down metrics: {e}")

            logging.info("=== LG-SOTF Application Shutdown Complete ===\n")

        except Exception as e:
            logging.error(f"Error during shutdown: {e}", exc_info=True)

    async def _shutdown_agents(self):
        """Shutdown all registered agents."""
        try:
            from lg_sotf.agents.registry import agent_registry

            logging.info("Shutting down agents...")
            await agent_registry.cleanup_all_agents()
            logging.info("‚úì All agents stopped")

        except Exception as e:
            logging.warning(f"‚ö† Error shutting down agents: {e}")

    async def _shutdown_storage(self):
        """Shutdown storage connections."""
        storage_tasks = []

        # Schedule PostgreSQL cleanup
        if self.postgres_storage:
            try:
                storage_tasks.append(
                    asyncio.create_task(self.postgres_storage.close())
                )
            except Exception as e:
                logging.warning(f"‚ö† Error scheduling PostgreSQL close: {e}")

        # Schedule Redis cleanup
        if self.redis_storage:
            try:
                storage_tasks.append(
                    asyncio.create_task(self.redis_storage.close())
                )
            except Exception as e:
                logging.warning(f"‚ö† Error scheduling Redis close: {e}")

        # Wait for storage cleanup with timeout
        if storage_tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*storage_tasks, return_exceptions=True),
                    timeout=5.0
                )
                logging.info("‚úì Storage connections closed")
            except asyncio.TimeoutError:
                logging.warning("‚ö† Storage cleanup timed out")
            except Exception as e:
                logging.warning(f"‚ö† Error during storage cleanup: {e}")

    async def health_check(self) -> bool:
        """Perform comprehensive health check.

        Returns:
            bool: True if all components healthy, False otherwise
        """
        try:
            health_results = {
                'config_manager': False,
                'state_manager': False,
                'workflow_engine': False,
                'postgres_storage': False,
                'redis_storage': False,
                'agents': False
            }

            # Check configuration
            if self.config_manager:
                health_results['config_manager'] = True

            # Check state manager
            if self.state_manager:
                health_results['state_manager'] = True

            # Check workflow engine
            if self.workflow_engine:
                health_results['workflow_engine'] = True

            # Check PostgreSQL
            if self.postgres_storage:
                health_results['postgres_storage'] = await self.postgres_storage.health_check()

            # Check Redis
            if self.redis_storage:
                health_results['redis_storage'] = await self.redis_storage.health_check()

            # Check agents
            try:
                from lg_sotf.agents.registry import agent_registry

                # Check if any agent is healthy
                if agent_registry.agent_exists("ingestion_instance"):
                    ingestion_agent = agent_registry.get_agent("ingestion_instance")
                    if hasattr(ingestion_agent, 'health_check'):
                        health_results['agents'] = await ingestion_agent.health_check()
                    else:
                        health_results['agents'] = ingestion_agent.initialized

            except Exception as e:
                logging.debug(f"Agent health check error: {e}")
                health_results['agents'] = False

            # Record component health metrics
            if self.metrics:
                for component, status in health_results.items():
                    self.metrics.set_gauge(f"health_{component}", 1 if status else 0)

            # Calculate overall health
            overall_health = all(health_results.values())

            # Log unhealthy components
            unhealthy = [comp for comp, status in health_results.items() if not status]
            if unhealthy:
                logging.debug(f"Unhealthy components: {', '.join(unhealthy)}")

            return overall_health

        except Exception as e:
            logging.error(f"Health check failed: {e}", exc_info=True)
            return False

    async def process_single_alert(self, alert_id: str, alert_data: dict) -> dict:
        """Process a single alert through the workflow.

        This method is used for testing and manual alert processing.

        Args:
            alert_id: Alert identifier
            alert_data: Alert data dictionary

        Returns:
            dict: Workflow result

        Raises:
            LG_SOTFError: If workflow engine not initialized
        """
        try:
            if not self.workflow_engine:
                raise LG_SOTFError("Workflow engine not initialized")

            logging.info(f"Processing single alert: {alert_id}")

            result = await self.workflow_engine.execute_workflow(alert_id, alert_data)

            logging.info(f"Alert {alert_id} processed successfully")
            return result

        except Exception as e:
            logging.error(f"Failed to process alert {alert_id}: {e}", exc_info=True)
            raise

    def get_application_status(self) -> dict:
        """Get comprehensive application status.

        Returns:
            dict: Application status information
        """
        try:
            status = {
                'running': self.running,
                'initialized': self.initialized,
                'active_workflow_tasks': len(self._active_tasks),
                'last_ingestion_poll': self._last_ingestion_poll.isoformat() if self._last_ingestion_poll else None,
                'last_health_check': self._last_health_check.isoformat() if self._last_health_check else None,
                'components': {
                    'config_manager': self.config_manager is not None,
                    'state_manager': self.state_manager is not None,
                    'workflow_engine': self.workflow_engine is not None,
                    'audit_logger': self.audit_logger is not None,
                    'metrics': self.metrics is not None
                },
                'storage': {
                    'postgres': self.postgres_storage is not None,
                    'redis': self.redis_storage is not None
                }
            }

            # Add agent status
            try:
                from lg_sotf.agents.registry import agent_registry
                status['agents'] = agent_registry.get_registry_stats()
            except Exception as e:
                logging.warning(f"Error getting agent status: {e}")
                status['agents'] = {'error': str(e)}

            return status

        except Exception as e:
            logging.error(f"Error getting application status: {e}", exc_info=True)
            return {'error': str(e)}
